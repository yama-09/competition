{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "NAME = \"baseline001\"\n",
    "FOLDS = 5  # kfoldの数\n",
    "\n",
    "import os \n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import category_encoders as ce\n",
    "import xfeat\n",
    "import texthero as hero\n",
    "from lightgbm import LGBMModel\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoost\n",
    "from catboost import Pool\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#a = pd.read_csv('~/Desktop/job.csv',encoding='cp932')\n",
    "a = pd.read_csv('~/Desktop/job.csv')\n",
    "\n",
    "a[\"turnover\"]        = a[\"natl_unempct\"].fillna(a[\"natl_unempct\"].mean())\n",
    "a[\"employment\"]      = a[\"emppctchange\"].fillna(a[\"emppctchange\"].mean())\n",
    "a[\"new_employment\"]  = a[\"jobchange\"].fillna(a[\"jobchange\"].mean())\n",
    "a[\"income\"]          = a[\"pincomepcgrowth\"].fillna(a[\"pincomepcgrowth\"].mean())\n",
    "a[\"entry\"]           = a[\"estabsentryrtchange\"].fillna(a[\"estabsentryrtchange\"].mean())\n",
    "a[\"exit\"]            = a[\"estabsexitrtchange\"].fillna(a[\"estabsexitrtchange\"].mean())\n",
    "a[\"land_price\"]      = a[\"landpi\"].fillna(a[\"landpi\"].mean())\n",
    "a[\"welfare\"]         = a[\"realpubwelpc\"].fillna(a[\"realpubwelpc\"].mean())\n",
    "a[\"medical\"]         = a[\"realhealthspendpc\"].fillna(a[\"realhealthspendpc\"].mean())\n",
    "a[\"edication\"]       = a[\"realcombedspendpc\"].fillna(a[\"realcombedspendpc\"].mean())\n",
    "a[\"prime\"]           = a[\"primert\"].fillna(a[\"primert\"].mean())\n",
    "a[\"tax\"]             = a[\"sltotaltax\"].fillna(a[\"sltotaltax\"].mean())\n",
    "\n",
    "\n",
    "# 数値変数×数値変数\n",
    "def get_cross_num_features(a):\n",
    "      b = pd.DataFrame()\n",
    "      #変更なし\n",
    "      b[\"year\"] = a[\"year\"]\n",
    "      b[\"employment\"] = a[\"employment\"]\n",
    "      b[\"new_employment\"] = a[\"new_employment\"]\n",
    "      b[\"income\"] = a[\"income\"]\n",
    "      b[\"entry\"] = a[\"entry\"]\n",
    "      b[\"exit\"] = a[\"exit\"]\n",
    "      b[\"land_price\"] = a[\"land_price\"]\n",
    "      b[\"welfare\"] = a[\"welfare\"]\n",
    "      b[\"medical\"] = a[\"medical\"]\n",
    "      b[\"edication\"] = a[\"edication\"]\n",
    "      b[\"prime\"] = a[\"prime\"]\n",
    "      b[\"tax\"] = a[\"tax\"]\n",
    "      #year\n",
    "      b[\"ye_em\"] = a[\"year\"]*a[\"employment\"]\n",
    "      b[\"ye_ne\"] = a[\"year\"]*a[\"new_employment\"]\n",
    "      b[\"ye_in\"] = a[\"year\"]*a[\"income\"]\n",
    "      b[\"ye_en\"] = a[\"year\"]*a[\"entry\"]\n",
    "      b[\"ye_ex\"] = a[\"year\"]*a[\"exit\"]\n",
    "      b[\"ye_la\"] = a[\"year\"]*a[\"land_price\"]\n",
    "      b[\"ye_we\"] = a[\"year\"]*a[\"welfare\"]\n",
    "      b[\"ye_me\"] = a[\"year\"]*a[\"medical\"]\n",
    "      b[\"ye_ed\"] = a[\"year\"]*a[\"edication\"]\n",
    "      b[\"ye_pr\"] = a[\"year\"]*a[\"prime\"]\n",
    "      b[\"ye_ta\"] = a[\"year\"]*a[\"tax\"]\n",
    "      #employment\n",
    "      b[\"em_ne\"] = a[\"employment\"]*a[\"new_employment\"]\n",
    "      b[\"em_in\"] = a[\"employment\"]*a[\"income\"]\n",
    "      b[\"em_en\"] = a[\"employment\"]*a[\"entry\"]\n",
    "      b[\"em_ex\"] = a[\"employment\"]*a[\"exit\"]\n",
    "      b[\"em_la\"] = a[\"employment\"]*a[\"land_price\"]\n",
    "      b[\"em_we\"] = a[\"employment\"]*a[\"welfare\"]\n",
    "      b[\"em_me\"] = a[\"employment\"]*a[\"medical\"]\n",
    "      b[\"em_ed\"] = a[\"employment\"]*a[\"edication\"]\n",
    "      b[\"em_pr\"] = a[\"employment\"]*a[\"prime\"]\n",
    "      b[\"em_ta\"] = a[\"employment\"]*a[\"tax\"]\n",
    "      #new_employment\n",
    "      b[\"ne_in\"] = a[\"new_employment\"]*a[\"income\"]\n",
    "      b[\"ne_en\"] = a[\"new_employment\"]*a[\"entry\"]\n",
    "      b[\"ne_ex\"] = a[\"new_employment\"]*a[\"exit\"]\n",
    "      b[\"ne_la\"] = a[\"new_employment\"]*a[\"land_price\"]\n",
    "      b[\"ne_we\"] = a[\"new_employment\"]*a[\"welfare\"]\n",
    "      b[\"ne_me\"] = a[\"new_employment\"]*a[\"medical\"]\n",
    "      b[\"ne_ed\"] = a[\"new_employment\"]*a[\"edication\"]\n",
    "      b[\"ne_pr\"] = a[\"new_employment\"]*a[\"prime\"]\n",
    "      b[\"ne_ta\"] = a[\"new_employment\"]*a[\"tax\"]\n",
    "      #income\n",
    "      b[\"in_en\"] = a[\"income\"]*a[\"entry\"]\n",
    "      b[\"in_ex\"] = a[\"income\"]*a[\"exit\"]\n",
    "      b[\"in_la\"] = a[\"income\"]*a[\"land_price\"]\n",
    "      b[\"in_we\"] = a[\"income\"]*a[\"welfare\"]\n",
    "      b[\"in_me\"] = a[\"income\"]*a[\"medical\"]\n",
    "      b[\"in_ed\"] = a[\"income\"]*a[\"edication\"]\n",
    "      b[\"in_pr\"] = a[\"income\"]*a[\"prime\"]\n",
    "      b[\"in_ta\"] = a[\"income\"]*a[\"tax\"]\n",
    "      #entry\n",
    "      b[\"en_ex\"] = a[\"entry\"]*a[\"exit\"]\n",
    "      b[\"en_la\"] = a[\"entry\"]*a[\"land_price\"]\n",
    "      b[\"en_we\"] = a[\"entry\"]*a[\"welfare\"]\n",
    "      b[\"en_me\"] = a[\"entry\"]*a[\"medical\"]\n",
    "      b[\"en_ed\"] = a[\"entry\"]*a[\"edication\"]\n",
    "      b[\"en_pr\"] = a[\"entry\"]*a[\"prime\"]\n",
    "      b[\"en_ta\"] = a[\"entry\"]*a[\"tax\"]\n",
    "      #exit\n",
    "      b[\"ex_la\"] = a[\"exit\"]*a[\"land_price\"]\n",
    "      b[\"ex_we\"] = a[\"exit\"]*a[\"welfare\"]\n",
    "      b[\"ex_me\"] = a[\"exit\"]*a[\"medical\"]\n",
    "      b[\"ex_ed\"] = a[\"exit\"]*a[\"edication\"]\n",
    "      b[\"ex_pr\"] = a[\"exit\"]*a[\"prime\"]\n",
    "      b[\"ex_ta\"] = a[\"exit\"]*a[\"tax\"]\n",
    "      #land_price\n",
    "      b[\"la_we\"] = a[\"land_price\"]*a[\"welfare\"]\n",
    "      b[\"la_me\"] = a[\"land_price\"]*a[\"medical\"]\n",
    "      b[\"la_ed\"] = a[\"land_price\"]*a[\"edication\"]\n",
    "      b[\"la_pr\"] = a[\"land_price\"]*a[\"prime\"]\n",
    "      b[\"la_ta\"] = a[\"land_price\"]*a[\"tax\"]\n",
    "      #welfare\n",
    "      b[\"we_me\"] = a[\"welfare\"]*a[\"medical\"]\n",
    "      b[\"we_ed\"] = a[\"welfare\"]*a[\"edication\"]\n",
    "      b[\"we_pr\"] = a[\"welfare\"]*a[\"prime\"]\n",
    "      b[\"we_ta\"] = a[\"welfare\"]*a[\"tax\"]\n",
    "      #medical\n",
    "      b[\"me_ed\"] = a[\"medical\"]*a[\"edication\"]\n",
    "      b[\"me_pr\"] = a[\"medical\"]*a[\"prime\"]\n",
    "      b[\"me_ta\"] = a[\"medical\"]*a[\"tax\"]\n",
    "      #edication\n",
    "      b[\"ed_pr\"] = a[\"edication\"]*a[\"prime\"]\n",
    "      b[\"ed_ta\"] = a[\"edication\"]*a[\"tax\"]\n",
    "      #prime\n",
    "      b[\"pr_ta\"] = a[\"prime\"]*a[\"tax\"]\n",
    "      return b\n",
    "\n",
    "## count encoding\n",
    "def get_ce_features(input_df):\n",
    "    _input_df = input_df\n",
    "    cols = [\"state\"]\n",
    "    encoder = ce.CountEncoder()\n",
    "    output_df = encoder.fit_transform(_input_df[cols]).add_prefix(\"CE_\")\n",
    "    return output_df\n",
    "\n",
    "def agg_state(input_df):\n",
    "    _input_df = pd.concat([\n",
    "        input_df,\n",
    "        get_cross_num_features(input_df),\n",
    "    ], axis=1)\n",
    "    group_key = \"state\"  # カテゴリ変数\n",
    "    group_values = [# 集約される数値特徴量\n",
    "      \"ye_em\",\n",
    "      \"ye_ne\",\n",
    "      \"ye_in\",\n",
    "      \"ye_en\",\n",
    "      \"ye_ex\", \n",
    "      \"ye_la\",\n",
    "      \"ye_we\",\n",
    "      \"ye_me\",\n",
    "      \"ye_ed\",\n",
    "      \"ye_pr\",\n",
    "      \"ye_ta\",\n",
    "      #employment\n",
    "      \"em_ne\",\n",
    "      \"em_in\",\n",
    "      \"em_en\",\n",
    "      \"em_ex\", \n",
    "      \"em_la\",\n",
    "      \"em_we\",\n",
    "      \"em_me\",\n",
    "      \"em_ed\",\n",
    "      \"em_pr\",\n",
    "      \"em_ta\",\n",
    "      #new_employment\n",
    "      \"ne_in\",\n",
    "      \"ne_en\",\n",
    "      \"ne_ex\",\n",
    "      \"ne_la\",\n",
    "      \"ne_we\",\n",
    "      \"ne_me\",\n",
    "      \"ne_ed\",\n",
    "      \"ne_pr\",\n",
    "      \"ne_ta\",\n",
    "      #income\n",
    "      \"in_en\",\n",
    "      \"in_ex\",\n",
    "      \"in_la\",\n",
    "      \"in_we\",\n",
    "      \"in_me\",\n",
    "      \"in_ed\",\n",
    "      \"in_pr\",\n",
    "      \"in_ta\",\n",
    "      #entry\n",
    "      \"en_ex\",\n",
    "      \"en_la\",\n",
    "      \"en_we\",\n",
    "      \"en_me\",\n",
    "      \"en_ed\",\n",
    "      \"en_pr\",\n",
    "      \"en_ta\",\n",
    "      #exit\n",
    "      \"ex_la\",\n",
    "      \"ex_we\",\n",
    "      \"ex_me\",\n",
    "      \"ex_ed\",\n",
    "      \"ex_pr\",\n",
    "      \"ex_ta\",\n",
    "      #land_price\n",
    "      \"la_we\",\n",
    "      \"la_me\",\n",
    "      \"la_ed\",\n",
    "      \"la_pr\",\n",
    "      \"la_ta\",\n",
    "      #welfare\n",
    "      \"we_me\",\n",
    "      \"we_ed\",\n",
    "      \"we_pr\",\n",
    "      \"we_ta\",\n",
    "      #medical\n",
    "      \"me_ed\",\n",
    "      \"me_pr\",\n",
    "      \"me_ta\",\n",
    "      #edication\n",
    "      \"ed_pr\",\n",
    "      \"ed_ta\",\n",
    "      #prime\n",
    "      \"pr_ta\"\n",
    "    ]\n",
    "    agg_methods = [\"min\", \"max\", \"mean\", \"std\", \"count\"]  # 集約方法\n",
    "    output_df, cols = xfeat.aggregation(_input_df, group_key, group_values, agg_methods)\n",
    "    return output_df[cols].copy()\n",
    "\n",
    "def get_process_funcs():\n",
    "    funcs = [\n",
    "        get_ce_features,\n",
    "        get_cross_num_features,\n",
    "        agg_state\n",
    "    ]\n",
    "    return funcs\n",
    "\n",
    "def to_feature(input_df, funcs):\n",
    "    output_df = pd.DataFrame()\n",
    "    for func in tqdm(funcs, total=len(funcs)):\n",
    "        _df = func(input_df)\n",
    "        assert len(_df) == len(input_df), func.__name__\n",
    "        output_df = pd.concat([output_df, _df], axis=1)\n",
    "\n",
    "    return output_df\n",
    "\n",
    "train = a\n",
    "## preprocessing\n",
    "input_df = pd.concat([train]).reset_index(drop=True)  \n",
    "\n",
    "# all featrues\n",
    "process_funcs = get_process_funcs()\n",
    "output_df = to_feature(input_df, process_funcs)\n",
    "train_x = output_df.iloc[:len(train)]\n",
    "\n",
    "# target variable\n",
    "train_y = train[\"turnover\"]\n",
    "\n",
    "####ここまではクリア\n",
    "\n",
    "\n",
    "def tree_importance(train_x,train_y):\n",
    "        # visualize feature importance\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        model= LR()\n",
    "        model.fit(train_x,train_y)\n",
    "        regression_coefficient = model.coef_\n",
    "        _df = pd.DataFrame()\n",
    "        _df['feature_importance'] = regression_coefficient.T\n",
    "        _df['column'] = train_x.columns\n",
    "        feature_importance_df = pd.concat([feature_importance_df, _df], axis=0, ignore_index=True)\n",
    "        return  feature_importance_df\n",
    "\n",
    "importance_df = tree_importance(train_x,train_y)\n",
    "\n",
    "selected_num = 100   #50\n",
    "cols = importance_df.groupby(\"column\").mean().reset_index().sort_values(\"feature_importance\", ascending=False)[\"column\"].tolist()\n",
    "selected_cols = cols[:selected_num]\n",
    "train_x = train_x[selected_cols]\n",
    "\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test =train_test_split(train_x,train_y, random_state = 1)\n",
    "\n",
    "# モデルの箱の準備および学習\n",
    "lr= LR()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 予測値の算出\n",
    "y_pred_train = lr.predict(X_train)\n",
    "y_pred_test= lr.predict(X_test)\n",
    "\n",
    "#y_pred= lr.predict(test_X)\n",
    "#print(\"評価用の予測値 = \",y_pred)\n",
    "\n",
    "# MSEの算出\n",
    "mse_train = MSE(y_train, y_pred_train)\n",
    "mse_test = MSE(y_test, y_pred_test)\n",
    "\n",
    "# RMSEの算出\n",
    "rmse_train = np.sqrt(mse_train)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "#MAEの算出\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "#MAPEの算出\n",
    "mape_train = np.mean(np.abs((y_train - y_pred_train) / y_pred_train)) * 100\n",
    "mape_test = np.mean(np.abs((y_test - y_pred_test) / y_pred_test)) * 100\n",
    "\n",
    "#RMSPEの算出\n",
    "rmspe_train = np.sqrt(np.mean(((y_train - y_pred_train) / y_pred_train)**2))*100\n",
    "rmspe_test = np.sqrt(np.mean(((y_test - y_pred_test) / y_pred_test)**2))*100\n",
    "\n",
    "#R2の算出\n",
    "R2_train = r2_score(y_train,y_pred_train) \n",
    "R2_test = r2_score(y_test,y_pred_test) \n",
    "\n",
    "print()\n",
    "print(\"train_MAE=\",mae_train)\n",
    "print(\"train_MSE=\",mse_train)\n",
    "print(\"train_RMSE = \",rmse_train)\n",
    "print(\"train_MAPE = \",mape_train)\n",
    "print(\"train_RMSPE = \",rmspe_train)\n",
    "print(\"train_R2 = \",R2_train)\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"test_MAE=\",mae_test)\n",
    "print(\"test_MSE=\",mse_test)\n",
    "print(\"test_RMSE = \",rmse_test)\n",
    "print(\"test_MAPE = \",mape_test)\n",
    "print(\"test_RMSPE = \",rmspe_test)\n",
    "print(\"test_R2 = \",R2_test)\n",
    "\n",
    "regression_coefficient = lr.coef_\n",
    "\n",
    "df = pd.DataFrame(regression_coefficient.T,\n",
    "                 index=[train_x.columns.values],\n",
    "                 columns=[\"feature_importance\"])\n",
    "df = df.abs()\n",
    "sort = df.sort_values('feature_importance', ascending=False)\n",
    "\n",
    "df1 = pd.DataFrame(regression_coefficient.T,\n",
    "                 index=[train_x.columns.values],\n",
    "                 columns=[\"feature_importance\"])\n",
    "df1 = df.abs()\n",
    "sort1 = df1.sort_values('feature_importance', ascending=False)\n",
    "\n",
    "#print(sort.head(30))\n",
    "\n",
    "\"\"\"\n",
    "y         = y_train\n",
    "predict_y = y_pred_train\n",
    "\n",
    "# グラフエリアを設定し、散布図を描く。\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y, predict_y)\n",
    "\n",
    "# yの最大値、最小値を計算する。\n",
    "y_max = np.max(y)\n",
    "y_min = np.min(y)\n",
    "\n",
    "# predict_yの最大値、最小値を計算する。\n",
    "predict_y_max = np.max(predict_y)\n",
    "predict_y_min = np.min(predict_y)\n",
    "\n",
    "axis_max = max(y_max, predict_y_max)\n",
    "axis_min = min(y_min, predict_y_min)\n",
    "\n",
    "# 全てのプロットが収まるようにするには、yとpredict_y両方のうち\n",
    "# 最も小さい値、最も大きい値を縦軸横軸の範囲にすればいい。\n",
    "axis_max = axis_max + (axis_max-axis_min)*0.05\n",
    "axis_min = axis_min + (axis_max-axis_min)*0.05\n",
    "\n",
    "# y=predicted_yの直線を引く。\n",
    "plt.plot([axis_min, axis_max], [axis_min, axis_max], 'k')\n",
    "\n",
    "plt.xlim(axis_min, axis_max)\n",
    "plt.ylim(axis_min, axis_max)\n",
    "\n",
    "plt.xlabel('y')\n",
    "plt.ylabel('predict_y')\n",
    "\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# 学習済みモデルの各変数の係数を取得\n",
    "regression_coefficient = lr.coef_\n",
    "\n",
    "# 行ラベル･列ラベルを付与してDataFrameに変換\n",
    "df = pd.DataFrame(regression_coefficient.T,\n",
    "             index = [X.columns.values],\n",
    "             columns = ['Regression coefficient'])\n",
    "df = df.abs()\n",
    "sort = df.sort_values('Regression coefficient',ascending=False)\n",
    "print(sort.head(40))\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
