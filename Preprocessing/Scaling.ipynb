{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0960b07b",
   "metadata": {},
   "source": [
    "#### Attention\n",
    "\n",
    "そもそも決定木を使用する際は，特徴量に対する対数化や，0から1の範囲に正規化するような大小関係が保存される変換の影響はほとんどありません．数値の大小関係で学習するモデルであるため，基本的にスケーリングを行う必要がありません．\n",
    "\n",
    "\n",
    "一方で，線形回帰などはスケールの大きい変数ほど回帰係数が小さくなり，正則化がかかりにくいといった問題が生じてしまうので，NN含めスケーリングを行ったほうがいいことが多いです．(後述しますが二値変数や疎ベクトルに対してはスケーリングをしないほうが良い場合もあります．)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7355319a",
   "metadata": {},
   "source": [
    "#### StandardScaler\n",
    "\n",
    "各変数をその平均の差をとり，標準偏差で割ることで平均0，分散1の変数に変換します．疎ベクトルの場合は，平均値で差をとることで密ベクトルに変換してしまうため，モデルによっては疎ベクトルを前提に最適化していることもあり不適な場合があります．また，二値変数で偏りがあるときは標準偏差が小さな値になるため，変換後の値が非常に大きくなってしまう場合があり，注意が必要です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb62a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train[num_cols])\n",
    "train[num_cols] = scaler.transform(train[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f120827",
   "metadata": {},
   "source": [
    "#### MinMaxScaler\n",
    "\n",
    "各変数をその最小値で差をとり，最大値と最小値の差で割ることで各変数の最小値を0，最大値を1に変換します．極端に大きな・小さな値があると，その値に引っ張られたスケーリングをしてしまい悪影響を及ぼす可能性があるため注意が必要です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[num_cols])\n",
    "train[num_cols] = scaler.transform(train[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba6a6e9",
   "metadata": {},
   "source": [
    "#### RobustScaler\n",
    "\n",
    "極端に大きな・小さな値がある場合に使えるスケーリングです。標準では，各変数をその中央値で差をとり，75パーセンタイル値と25パーセンタイル値の差で割ることで各変数の中央値を0に変換します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c9304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler(quantile_range=(25.0, 75.0))\n",
    "scaler.fit(train[num_cols])\n",
    "train[num_cols] = scaler.transform(train[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a94d6",
   "metadata": {},
   "source": [
    "#### RankGauss\n",
    "\n",
    "各変数を順位に変換して正規分布になるように変換します．NNモデルにおいて他のスケーリングよりも良い性能を示すことがあるとのことで，QuantileTransformerを使い，n_quantilesの値を十分に大きくしてoutput_distributionを'normal'に指定することで，実装することができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "scaler = QuantileTransformer(\n",
    "    n_quantiles=100,\n",
    "    random_state=42,\n",
    "    output_distribution='normal'\n",
    ")\n",
    "scaler.fit(train[num_cols])\n",
    "train[num_cols] = scaler.transform(train[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
